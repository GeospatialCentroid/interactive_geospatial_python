{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64666606-617a-4098-902f-1855e1a9bcd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Geospatial Python\n",
    "## Temporal assessment using command line arguments \n",
    "Setup: https://carpentries-incubator.github.io/geospatial-python/index.html\n",
    "\n",
    "Based on instruction: https://carpentries-incubator.github.io/geospatial-python/09-raster-calculations.html\n",
    "\n",
    "Boundary data source - https://burnseverity.cr.usgs.gov/ravg/data-access, searched for \"cameron peak\"\n",
    "\n",
    "This notebook does the following:\n",
    "- Loads a boundary file of a fire boundary\n",
    "- Searches for satellite data within the area and during the growing season for a specific year\n",
    "- Takes several of the retrieved satellite images and merges them together to get complete coverage\n",
    "- Translates the satellite data into a value representing vegetative growth (Normalized Difference Vegetation Index, NDVI)\n",
    "- Classifies and generates statisitics of the vegetative growth, saves the output as both text and geotiff \n",
    "\n",
    "We'll want to compare different years to see pre, post, and potentially other years of vegetative growth within a burn area.\n",
    "To do this, we'll leverage a library called *papermill*(https://github.com/nteract/papermill) allowing us to pass parameters to the notebook which will dynamically load, analyze, and save our results for a specific year of satellite data.\n",
    "\n",
    "When we deploy this script to a HPC environment, running mulitple instances of it will allow us to much more rapidly get our results.\n",
    "\n",
    "Here's one call of this script for the year 2021:\n",
    "\n",
    "```\n",
    "papermill Boundary\\ Raster\\ Classification.ipynb output_2021.ipynb -p year 2021\n",
    "```\n",
    "\n",
    "Before executing the code cells, be sure to **fill in the blanks** by replacing the \"_____\" as appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be117d77-3fef-4594-b7eb-ad0f09e38554",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pystac\n",
    "import geopandas as gpd\n",
    "import folium # to make interactive maps\n",
    "import rioxarray\n",
    "from rioxarray import merge\n",
    "from pystac_client import Client # to query STAC API endpoint\n",
    "\n",
    "import geojson # to parse spatial data format\n",
    "import folium # to create an interactive map\n",
    "from folium.plugins import Draw # to allow drawing\n",
    "\n",
    "# Create a variable to determine if the notebook is being run locally\n",
    "local_run=False\n",
    "if local_run:\n",
    "    # this package is problematic on remote computers\n",
    "    from localtileserver import TileClient, get_folium_tile_layer # to visualize the geotiff\n",
    "\n",
    "import numpy as np # to work with numbered lists\n",
    "import xarray # to preserve spatial metadata when working with numbered lists\n",
    "\n",
    "import earthpy.plot as ep # for drawing a legend\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.colors import ListedColormap # to color our classified data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748f8e3-5502-40c2-a743-58ce8593a684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Start by setting a variable for the year\n",
    "# THIS CODE CELL has the tag 'parameters' (see https://github.com/nteract/papermill)\n",
    "# This tag will allow us to overwrite the contents of the cell using the command line, which also creates a new notebook\n",
    "# We'll set a 'year' variable and look at the satellite image just before the fire broke out\n",
    "# Note: The Cameron Peak fire occured August 13, 2020\n",
    "year = \"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b5709-bf7c-4cc6-9d94-488e4b028bf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in our boundary data\n",
    "boundary = gpd.read_file(\"data/co4060910587920200813_20180915_20210907_burn_bndy.zip\")\n",
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85caab4-00f1-49d4-bae8-905425b2420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the data types\n",
    "print(boundary.\"_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b60175-e30e-4731-8901-7be2d147434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the map file 'boundary'\n",
    "# Use the file's lat and long column to center the map\n",
    "m = folium.Map([boundary.iloc[1]['BurnBndLat'],boundary.iloc[1]['BurnBndLon']], zoom_start = 10)\n",
    "\n",
    "# Change the column type for display on the interactive map \n",
    "boundary['Ig_Date'] = boundary['Ig_Date'].astype(str) # otherwise error \"Object of type Timestamp is not JSON serializable\"\n",
    "\n",
    "# Add the layer to the map\n",
    "folium.GeoJson(boundary).add_to(m)\n",
    "\n",
    "# Show the map\n",
    "\"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347de8a-caf9-4878-b5d5-226409665e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the boundary variable\n",
    "boundary.\"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f23e3a-4d87-4100-a4d6-15aedd60376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the boundary CRS\n",
    "boundary.\"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126a700-a913-4a08-8db7-0fd73de4ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert tne boundary to use CRS '4326'\n",
    "boundary=boundary.to_crs(\"_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2852564-6422-4340-8119-bddf9d4fd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the rows to get a complete bounds\n",
    "poly=boundary.geometry.union_all()\n",
    "poly.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555373c1-0a02-45c6-b1b2-5651aac5b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform metadata search from Sentinel-2, Level 2A, to retrieve Cloud Optimized GeoTiffs (COGs)\n",
    "api_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "# Open the api\n",
    "client = Client.open(api_url)\n",
    "# Store a variable pointing to the collection of interest\n",
    "# Note: collection ID is taken from Sentinel-2 Level 2A - https://radiantearth.github.io/stac-browser/#/external/earth-search.aws.element84.com/v1/collections/sentinel-2-c1-l2a\n",
    "collection = \"sentinel-2-l2a\" \n",
    "\n",
    "search = client.search(\n",
    "    collections=[collection],\n",
    "    bbox=poly.bounds,# https://datatracker.ietf.org/doc/html/rfc7946#section-5\n",
    "    datetime=str(year)+\"-07-01/\"+str(year)+\"-07-31\",\n",
    "    query=[\"eo:cloud_cover<20\"],\n",
    "    limit=10\n",
    ")\n",
    "# Show the number of scenes (i.e. the portion of the footage recorded by the satellite)\n",
    "print(search.matched())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159333b-0ea9-497f-ab72-41e2888a5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the items by cloud_cover\n",
    "items = search.item_collection()\n",
    "\n",
    "items_sorted = sorted(items, key=lambda x: x.properties[\"eo:\"_____\"\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4687dd-f555-417e-a12c-c3013d0d0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets short list the items which we'll merge later and then clip\n",
    "# Start by gathering the hrefs\n",
    "red_item_hrefs=[]\n",
    "nir_item_hrefs=[]\n",
    "\n",
    "for i in items_sorted[0:3]:\n",
    "    print(i)\n",
    "    red_item_hrefs.append(i.assets[\"red\"].href)\n",
    "    nir_item_hrefs.append(i.assets[\"nir08\"].href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348fbfb-9806-4eab-98ef-eef9af0870ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the map file 'boundary'\n",
    "# Use the file's lat and long column to center the map\n",
    "m = folium.Map([boundary.iloc[1]['BurnBndLat'],boundary.iloc[1]['BurnBndLon']], zoom_start = 10)\n",
    "\n",
    "# Add the boundary\n",
    "folium.GeoJson(boundary).add_to(m)\n",
    "\n",
    "\n",
    "# View the red band 'items' on the map\n",
    "if local_run:\n",
    "    for id, i in enumerate(red_item_hrefs):\n",
    "        tiles = TileClient(i) # create tiles client\n",
    "        tile_layer = get_folium_tile_layer(tiles, name='red_'+str(id)) # create tile layer\n",
    "        tile_layer.add_to(m)\n",
    "else:\n",
    "    # We'll just show the raster boundaries\n",
    "    # Some extra modules and a library are required for this\n",
    "    from shapely.geometry import box # To create a box\n",
    "    from shapely.ops import transform # The shapely transform module  \n",
    "    import pyproj # A reprojection library\n",
    "    # Create the transformer\n",
    "    project = pyproj.Transformer.from_crs(rioxarray.open_rasterio(red_item_hrefs[0]).rio.crs.to_epsg(), 4326, always_xy=True).transform\n",
    "    \n",
    "    # Apply the transformation\n",
    "    for id, i in enumerate(red_item_hrefs):\n",
    "        raster = rioxarray.open_rasterio(red_item_hrefs[id])\n",
    "        # Create boundary boxes\n",
    "        bbox = box(*raster.rio.bounds())\n",
    "        bbox_transformed = transform(project, bbox)\n",
    "        folium.GeoJson(bbox_transformed,\n",
    "            style_function=lambda feature: {\n",
    "            \"color\": \"purple\",\n",
    "        }).add_to(m)\n",
    "\n",
    "# show the bounds of the file 'boundary'\n",
    "folium.Rectangle(\n",
    "    bounds=[[poly.bounds[1], poly.bounds[0]], [poly.bounds[3], poly.bounds[2]]],\n",
    ").add_to(m)\n",
    "\n",
    "draw = Draw(export=True)\n",
    "draw.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# Show the map\n",
    "\"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eba60b-56dd-4351-8122-d121fea0f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the rasters and store them in separate lists using the argument masked=True.\n",
    "\n",
    "red_rasters=[]\n",
    "for i in red_item_hrefs:\n",
    "    red_rasters.append(rioxarray.open_rasterio(i, masked=True))\n",
    "\n",
    "nir_rasters=[]\n",
    "for i in nir_item_hrefs:\n",
    "    nir_rasters.append(rioxarray.open_rasterio(i, masked=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77b7e0-76b2-4767-b91d-6966585e9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our boundry to the CRS of the raster\n",
    "boundary_new_crs=boundary.to_crs(red_rasters[0].rio.crs)\n",
    "poly_new_crs=boundary_new_crs.geometry.union_all()\n",
    "\n",
    "# Show the bounds\n",
    "poly_new_crs.\"_____\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e22221-f4aa-4973-9522-b82620fcf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge our files into one\n",
    "\n",
    "red_merged = merge.merge_arrays(red_rasters,poly_new_crs.bounds)\n",
    "\n",
    "nir_merged = merge.merge_arrays(nir_rasters,poly_new_crs.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8954c12-3576-423a-ad7b-e30e6caafde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the two merged files. Add the 'year' variable as part of the file name\n",
    "\n",
    "red_merged.rio.to_raster(\"red_merged\"+str(year)+\".tif\")\n",
    "\n",
    "nir_merged.rio.to_raster(\"nir_merged\"+str(year)+\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab36b52-8519-4bdb-a359-f9f7dd1018f2",
   "metadata": {},
   "source": [
    "## Raster Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ec523-f2dd-4643-8a62-b44a7a79f524",
   "metadata": {},
   "source": [
    "## Crop raster data with polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2d748-3a59-4ef0-896b-977249e5cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shapes of the two rasters\n",
    "print(red_merged.shape, nir_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72625b-335f-471e-bc6e-11f50e90b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As their width and height do not match, \n",
    "# use reproject_match to both reproject and clip the raster to the CRS.\n",
    "red_merged_matched = red_merged.rio.reproject_match(nir_merged,nodata=np.nan ) # Set NaN as NoData\n",
    "print(red_merged_matched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c47f2-84e8-46f3-b526-026f2c76238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the NDVI as a new raster \n",
    "ndvi = (nir_merged - red_merged_matched)/ (nir_merged + red_merged_matched)\n",
    "print(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe69f56-0102-4ac8-87aa-d85489620e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputted NDVI\n",
    "ndvi.\"_____\"()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a5907-390d-4f81-a986-842ead136749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram to see the spread of values accross 50 bins\n",
    "ndvi.plot.hist(bins=\"_____\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e252d-50c0-44d7-af7e-e6c21ae30977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the color plot by specifying the intervals\n",
    "class_bins = (-1, 0., 0.2, 0.7, 1)\n",
    "ndvi.plot(levels=class_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed384f7-2edd-46f7-a286-f005be95b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values can be interpolated from the values of neighbouring grid cells using the .interpolate_na method. \n",
    "ndvi_nonan = ndvi.interpolate_na(dim=\"x\")\n",
    "\n",
    "# Save the output with the 'year' variable as part of the file name\n",
    "ndvi_nonan.rio.to_raster(\"NDVI\"+str(year)+\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520a820-6e7d-4d33-994b-bb308abbb8a4",
   "metadata": {},
   "source": [
    "## Classifying Continuous Rasters in Python\n",
    "\n",
    "Reduce the complexity of the map by classifying it. \n",
    "\n",
    "Classification involves assigning each pixel in the raster to a class based on its value. \n",
    "\n",
    "In Python, we can accomplish this using the *numpy.digitize* function\n",
    "\n",
    "Note: by default, each class includes the left but not the right bound. This is not an issue here, since the computed range of NDVI values is fully contained in the open interval (-1; 1) (see exercise above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14532298-e0c2-4f30-be83-320db74f62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray\n",
    "\n",
    "# Defines the bins for pixel values\n",
    "class_bins = (-1, 0., 0.2, 0.7, 1)\n",
    "\n",
    "# The numpy.digitize function returns an unlabeled array, in this case, a\n",
    "# classified array without any metadata. That doesn't work--we need the\n",
    "# coordinates and other spatial metadata. We can get around this by using\n",
    "# \"xarray.apply_ufunc\", which can run the function across the data array while\n",
    "# preserving metadata.\n",
    "ndvi_classified = xarray.apply_ufunc(\n",
    "    np.digitize,\n",
    "    ndvi_nonan,\n",
    "    class_bins,\n",
    "    dataset_fill_value=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289200b-f8c6-474e-9fbc-36a338ad182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classified NDVI, customizing the plot with proper title and legend\n",
    "import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define color map of the map legend\n",
    "ndvi_colors = [\"blue\", \"gray\", \"green\", \"darkgreen\"]\n",
    "ndvi_cmap = ListedColormap(ndvi_colors)\n",
    "\n",
    "# Define class names for the legend\n",
    "category_names = [\n",
    "    \"Water\",\n",
    "    \"No Vegetation\",\n",
    "    \"Sparse Vegetation\",\n",
    "    \"Dense Vegetation\"\n",
    "]\n",
    "\n",
    "# We need to know in what order the legend items should be arranged\n",
    "category_indices = list(range(len(category_names)))\n",
    "\n",
    "# Make the plot\n",
    "im = ndvi_classified.plot(cmap=ndvi_cmap, add_colorbar=False)\n",
    "plt.title(\"Classified NDVI\")\n",
    "# earthpy helps us by drawing a legend given an existing image plot and legend items, plus indices\n",
    "ep.draw_legend(im_ax=im, classes=category_indices, titles=category_names)\n",
    "\n",
    "# Save the figure (optional)\n",
    "# plt.savefig(\"NDVI_classified.png\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb2a36-2356-446a-90fd-efb33d0218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the classified NDVI raster object to a GeoTiff\n",
    "ndvi_classified.rio.to_raster(\"NDVI\"+str(year)+\"_classified.tif\", dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcf30c-f040-49dc-831c-ee6f41fbc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of the classified data\n",
    "ndvi_classified.plot.\"_____\"()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fed711-155d-41cc-a016-e255ac541beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both raster datasets: NDVI.tif and NDVI_classified.tif. \n",
    "# Then, calculate zonal statistics for each class_bins. Inspect the output of the zonal_stats function.\n",
    "\n",
    "from xrspatial import zonal_stats\n",
    "stats=zonal_stats(ndvi_classified.squeeze(), ndvi.squeeze())\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ce9c1-9a21-4823-97a9-ab4b797cdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output counts to a csv file\n",
    "\n",
    "# First check if this file exists\n",
    "file_path = \"output.csv\"\n",
    "try: \n",
    "    with open(file_path, 'x') as file: \n",
    "        file.write(\"year,\"+\",\".join(category_names)+ \"\\n\") \n",
    "except FileExistsError: \n",
    "    pass\n",
    "\n",
    "# Append to the existing file\n",
    "with open(file_path, 'a') as file: \n",
    "    file.write(str(year)+\",\"+\",\".join(str(x) for x in stats[\"count\"])+ \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
