{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64666606-617a-4098-902f-1855e1a9bcd2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Geospatial Python\n",
    "## Temporal assessment using command line arguments \n",
    "Setup: https://carpentries-incubator.github.io/geospatial-python/index.html\n",
    "\n",
    "Based on Instruction: https://carpentries-incubator.github.io/geospatial-python/09-raster-calculations.html\n",
    "\n",
    "Boundary data source - https://burnseverity.cr.usgs.gov/ravg/data-access, searched for \"cameron peak\"\n",
    "\n",
    "This notebook does the following:\n",
    "- Loads a boundary file of a fire boundary\n",
    "- Searches for satellite data within the area and during the growing season for a specific year (and clips the data)\n",
    "- Translates the satellite data into a value representing vegetative growth\n",
    "- Classifies and generates statisitics of the vegetative growth, saves output as both text and geotiff \n",
    "\n",
    "We'll want to compare different years to see pre, post, and potentially other years of vegetive growth within the burn area\n",
    "To do this, we'll leverage a library called papermill (https://github.com/nteract/papermill) allowing us to pass parameters to the notebook which will dynamically load, analyze, and save our results for a specific year of satellite data.\n",
    "\n",
    "When we deploy this script to an HPC environment, running mulitple instances of it will allow us to much more rapidly get our results.\n",
    "\n",
    "Here's one call of this script:\n",
    "\n",
    "```\n",
    "papermill Boundary\\ Raster\\ Classification.ipynb output_2021.ipynb -p year 2021\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be117d77-3fef-4594-b7eb-ad0f09e38554",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pystac\n",
    "import geopandas as gpd\n",
    "import folium # to make interactive maps\n",
    "import rioxarray\n",
    "from rioxarray import merge\n",
    "from pystac_client import Client # to query STAC API endpoint\n",
    "\n",
    "import geojson # to parse spatial data format\n",
    "import folium # to create an interactive map\n",
    "from folium.plugins import Draw # to allow drawing\n",
    "from localtileserver import TileClient, get_folium_tile_layer # to visualize the geotif \n",
    "\n",
    "import numpy as np\n",
    "import xarray\n",
    "import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748f8e3-5502-40c2-a743-58ce8593a684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# start by setting a variable for the year\n",
    "# The code cell has the tag 'parameters' (see https://github.com/nteract/papermill)\n",
    "# this tag will allow us to replace the contents of the cell using the command line\n",
    "# Note: The Cameron peak fire occured August 13, 2020\n",
    "year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b5709-bf7c-4cc6-9d94-488e4b028bf4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load in our boundary data\n",
    "boundary = gpd.read_file(\"data/co4060910587920200813_20180915_20210907_burn_bndy.shp\")\n",
    "boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85caab4-00f1-49d4-bae8-905425b2420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(boundary.columns)\n",
    "print(boundary.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b60175-e30e-4731-8901-7be2d147434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the map boundary\n",
    "\n",
    "boundary['Ig_Date'] = boundary['Ig_Date'].astype(str) # otherwise error \"Object of type Timestamp is not JSON serializable\"\n",
    "\n",
    "map = folium.Map([boundary.iloc[1]['BurnBndLat'],boundary.iloc[1]['BurnBndLon']], zoom_start = 10)\n",
    "folium.GeoJson(boundary).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5347de8a-caf9-4878-b5d5-226409665e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary.boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f23e3a-4d87-4100-a4d6-15aedd60376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126a700-a913-4a08-8db7-0fd73de4ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary=boundary.to_crs(\"4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2852564-6422-4340-8119-bddf9d4fd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly=boundary.geometry.union_all()\n",
    "poly.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555373c1-0a02-45c6-b1b2-5651aac5b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform metadata search from Sentinel-2, Level 2A, to retrieve Cloud Optimized GeoTiffs (COGs)\n",
    "api_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "# open the api\n",
    "client = Client.open(api_url)\n",
    "# store a variable pointing to the collection of interest\n",
    "# Note: collection ID is taken from Sentinel-2 Level 2A - https://radiantearth.github.io/stac-browser/#/external/earth-search.aws.element84.com/v1/collections/sentinel-2-c1-l2a\n",
    "collection = \"sentinel-2-l2a\" \n",
    "\n",
    "search = client.search(\n",
    "    collections=[collection],\n",
    "    bbox=poly.bounds,# https://datatracker.ietf.org/doc/html/rfc7946#section-5\n",
    "    datetime=str(year)+\"-07-01/\"+str(year)+\"-07-31\",\n",
    "    query=[\"eo:cloud_cover<20\"],\n",
    "    limit=10\n",
    ")\n",
    "# show the number of scenes (i.e. the portion of the footage recorded by the satellite)\n",
    "print(search.matched())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159333b-0ea9-497f-ab72-41e2888a5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the items and get the first\n",
    "items = search.item_collection()\n",
    "\n",
    "items_sorted = sorted(items, key=lambda x: x.properties[\"eo:cloud_cover\"]) # sorting and then selecting by cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4687dd-f555-417e-a12c-c3013d0d0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets short list the items which we'll merge later and then clip\n",
    "# we only need the hrefs\n",
    "red_item_hrefs=[]\n",
    "nir_item_hrefs=[]\n",
    "\n",
    "for i in items_sorted[0:3]:\n",
    "    print(i)\n",
    "    red_item_hrefs.append(i.assets[\"red\"].href)\n",
    "    nir_item_hrefs.append(i.assets[\"nir08\"].href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348fbfb-9806-4eab-98ef-eef9af0870ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = folium.Map([boundary.iloc[1]['BurnBndLat'],boundary.iloc[1]['BurnBndLon']], zoom_start = 10)\n",
    "folium.GeoJson(boundary).add_to(m)\n",
    "\n",
    "# view the items on the map\n",
    "for id, i in enumerate(red_item_hrefs):\n",
    "    tiles = TileClient(i) # create tiles client\n",
    "    tile_layer = get_folium_tile_layer(tiles, name='red_'+str(id)) # create tile layer\n",
    "    tile_layer.add_to(m)\n",
    "\n",
    "# show the bounds\n",
    "folium.Rectangle(\n",
    "    bounds=[[poly.bounds[1], poly.bounds[0]], [poly.bounds[3], poly.bounds[2]]],\n",
    ").add_to(m)\n",
    "\n",
    "draw = Draw(export=True)\n",
    "draw.add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eba60b-56dd-4351-8122-d121fea0f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the rasters and store in separate lists, using the argument masked=True.\n",
    "red_rasters=[]\n",
    "for i in red_item_hrefs:\n",
    "    red_rasters.append(rioxarray.open_rasterio(i, masked=True))\n",
    "\n",
    "nir_rasters=[]\n",
    "for i in nir_item_hrefs:\n",
    "    nir_rasters.append(rioxarray.open_rasterio(i, masked=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77b7e0-76b2-4767-b91d-6966585e9109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set out boundry to the crs of the raster\n",
    "boundary_new_crs=boundary.to_crs(red_rasters[0].rio.crs)\n",
    "poly_new_crs=boundary_new_crs.geometry.union_all()\n",
    "poly_new_crs.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e22221-f4aa-4973-9522-b82620fcf254",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_merged = merge.merge_arrays(red_rasters,poly_new_crs.bounds)\n",
    "nir_merged = merge.merge_arrays(nir_rasters,poly_new_crs.bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8954c12-3576-423a-ad7b-e30e6caafde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_merged.rio.to_raster(\"red_merged\"+str(year)+\".tif\")\n",
    "nir_merged.rio.to_raster(\"nir_merged\"+str(year)+\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab36b52-8519-4bdb-a359-f9f7dd1018f2",
   "metadata": {},
   "source": [
    "## Raster Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518ec523-f2dd-4643-8a62-b44a7a79f524",
   "metadata": {},
   "source": [
    "## Crop raster data with polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2d748-3a59-4ef0-896b-977249e5cc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shapes of the two rasters in the following way\n",
    "print(red_merged.shape, nir_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72625b-335f-471e-bc6e-11f50e90b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As their width and height do not match, use reproject_match to both reproject and clip the raster to the CRS and extent of another raster.\n",
    "red_merged_matched = red_merged.rio.reproject_match(nir_merged,nodata=np.nan ) # Set NaN as NoData\n",
    "print(red_merged_matched.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c47f2-84e8-46f3-b526-026f2c76238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the NDVI as a new raster \n",
    "ndvi = (nir_merged - red_merged_matched)/ (nir_merged + red_merged_matched)\n",
    "print(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe69f56-0102-4ac8-87aa-d85489620e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the output NDVI\n",
    "ndvi.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a5907-390d-4f81-a986-842ead136749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram to see the spread of values accross 50 bins\n",
    "ndvi.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e252d-50c0-44d7-af7e-e6c21ae30977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the color plot by specifying the intervals\n",
    "class_bins = (-1, 0., 0.2, 0.7, 1)\n",
    "ndvi.plot(levels=class_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed384f7-2edd-46f7-a286-f005be95b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values can be interpolated from the values of neighbouring grid cells using the .interpolate_na method. \n",
    "ndvi_nonan = ndvi.interpolate_na(dim=\"x\")\n",
    "\n",
    "# save the output\n",
    "ndvi_nonan.rio.to_raster(\"NDVI\"+str(year)+\".tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520a820-6e7d-4d33-994b-bb308abbb8a4",
   "metadata": {},
   "source": [
    "## Classifying Continuous Rasters in Python\n",
    "\n",
    "Reduce the complexity of the map by classifying it. \n",
    "\n",
    "Classification involves assigning each pixel in the raster to a class based on its value. \n",
    "\n",
    "In Python, we can accomplish this using the *numpy.digitize* function\n",
    "\n",
    "Note: by default, each class includes the left but not the right bound. This is not an issue here, since the computed range of NDVI values is fully contained in the open interval (-1; 1) (see exercise above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14532298-e0c2-4f30-be83-320db74f62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray\n",
    "\n",
    "# Defines the bins for pixel values\n",
    "class_bins = (-1, 0., 0.2, 0.7, 1)\n",
    "\n",
    "# The numpy.digitize function returns an unlabeled array, in this case, a\n",
    "# classified array without any metadata. That doesn't work--we need the\n",
    "# coordinates and other spatial metadata. We can get around this by using\n",
    "# \"xarray.apply_ufunc\", which can run the function across the data array while\n",
    "# preserving metadata.\n",
    "ndvi_classified = xarray.apply_ufunc(\n",
    "    np.digitize,\n",
    "    ndvi_nonan,\n",
    "    class_bins,\n",
    "    dataset_fill_value=np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289200b-f8c6-474e-9fbc-36a338ad182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the classified NDVI, customizing the plot with proper title and legend\n",
    "import earthpy.plot as ep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Define color map of the map legend\n",
    "ndvi_colors = [\"blue\", \"gray\", \"green\", \"darkgreen\"]\n",
    "ndvi_cmap = ListedColormap(ndvi_colors)\n",
    "\n",
    "# Define class names for the legend\n",
    "category_names = [\n",
    "    \"Water\",\n",
    "    \"No Vegetation\",\n",
    "    \"Sparse Vegetation\",\n",
    "    \"Dense Vegetation\"\n",
    "]\n",
    "\n",
    "# We need to know in what order the legend items should be arranged\n",
    "category_indices = list(range(len(category_names)))\n",
    "\n",
    "# Make the plot\n",
    "im = ndvi_classified.plot(cmap=ndvi_cmap, add_colorbar=False)\n",
    "plt.title(\"Classified NDVI\")\n",
    "# earthpy helps us by drawing a legend given an existing image plot and legend items, plus indices\n",
    "ep.draw_legend(im_ax=im, classes=category_indices, titles=category_names)\n",
    "\n",
    "# Save the figure\n",
    "# plt.savefig(\"NDVI_classified.png\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb2a36-2356-446a-90fd-efb33d0218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the classified NDVI raster object to a GeoTiff\n",
    "ndvi_classified.rio.to_raster(\"NDVI\"+str(year)+\"_classified.tif\", dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fcf30c-f040-49dc-831c-ee6f41fbc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_classified.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fed711-155d-41cc-a016-e255ac541beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load both raster datasets: NDVI.tif and NDVI_classified.tif. \n",
    "#Then, calculate zonal statistics for each class_bins. Inspect the output of the zonal_stats function.\n",
    "\n",
    "from xrspatial import zonal_stats\n",
    "stats=zonal_stats(ndvi_classified.squeeze(), ndvi.squeeze())\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ce9c1-9a21-4823-97a9-ab4b797cdfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output counts to a csv file\n",
    "file_path = \"output.csv\"\n",
    "try: \n",
    "    with open(file_path, 'x') as file: \n",
    "        file.write(\"year,\"+\",\".join(category_names)+ \"\\n\") \n",
    "except FileExistsError: \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc97c65-14ec-421f-8618-2a13c52bcc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open(file_path, 'a') as file: \n",
    "        file.write(str(year)+\",\"+\",\".join(str(x) for x in stats[\"count\"])+ \"\\n\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
